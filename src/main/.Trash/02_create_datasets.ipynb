{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos = []\n",
    "for i in range(1,28):\n",
    "    steps = map(lambda x: x.strip().split(\"\\t\")[1], open(\"../annotations/workflow_video_%02d.txt\" % i, \"r\").readlines()[1:])\n",
    "    videos.append(steps[24::25]) # keep 1 frame out of 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TrocarPlacement', 'Preparation', 'CalotTriangleDissection', 'ClippingCutting', 'GallbladderDissection', 'GallbladderPackaging', 'CleaningCoagulation', 'GallbladderRetraction']\n"
     ]
    }
   ],
   "source": [
    "unique_steps = list(reduce(lambda s1, s2: s1.union(s2), map(lambda s: set(s), videos)))\n",
    "\n",
    "# Manual writting of steps to have meaningful order\n",
    "ordered_unique_steps = \\\n",
    "    [\"TrocarPlacement\", \"Preparation\", \"CalotTriangleDissection\", \"ClippingCutting\", \"GallbladderDissection\",\n",
    "     \"GallbladderPackaging\", \"CleaningCoagulation\", \"GallbladderRetraction\"]\n",
    "p = len(ordered_unique_steps)\n",
    "\n",
    "if len(set(ordered_unique_steps).difference(set(unique_steps))) > 0:\n",
    "    raise Exception(\"Sets do not match\")\n",
    "else:\n",
    "    print ordered_unique_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This map will be used to get the index of a string step\n",
    "step_index = {v: k for k, v in zip(range(p), ordered_unique_steps)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of elements sanity check\n",
    "\n",
    "Let's check if the number of annotations extracted from annotations file match the number of images in the folder. Seems like they don't, there seem to be 1 or 2 frames more than annotations. Whatever, let's ignore the additional images and simply use the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "videos_annotations_len = []\n",
    "for steps in videos:\n",
    "    videos_annotations_len.append(len(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "videos_images_len = []\n",
    "files = map(lambda x: x.strip().replace(\".jpg\", \"\").split(\"-\"), open(\"../files.txt\", \"r\").readlines())\n",
    "groups = pd.DataFrame(files).groupby(0)\n",
    "for name, group in groups:\n",
    "    videos_images_len.append(len(group[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3057, 3058), (873, 874), (3214, 3216), (3681, 3682), (2057, 2058), (2936, 2937), (1499, 1500), (1822, 1824), (2181, 2183), (1545, 1546), (2132, 2133), (3445, 3447), (1602, 1604), (3243, 3245), (2720, 2722), (3093, 3095), (3055, 3056), (1700, 1701), (2959, 2961), (2025, 2027), (2757, 2759), (2574, 2575), (2044, 2045), (3994, 3995), (2986, 2987), (2500, 2502), (1861, 1863)]\n",
      "[-1 -1 -2 -1 -1 -1 -1 -2 -2 -1 -1 -2 -2 -2 -2 -2 -1 -1 -2 -2 -2 -1 -1 -1 -1\n",
      " -2 -2]\n"
     ]
    }
   ],
   "source": [
    "print zip(videos_annotations_len, videos_images_len)\n",
    "print np.array(videos_annotations_len) - np.array(videos_images_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data split\n",
    "\n",
    "Let's compute a train / val split and write the list of images / annotations in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = len(videos)\n",
    "# Test videos\n",
    "test_inds = set(np.random.choice(n, int(np.floor(n * 0.20)), replace=False))\n",
    "train_inds = set(range(n)) - test_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "set([18, 2, 3, 14, 6])\n",
      "Train\n",
      "set([0, 1, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26])\n"
     ]
    }
   ],
   "source": [
    "print \"Test\"\n",
    "print test_inds\n",
    "print \"Train\"\n",
    "print train_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_test = \"\"\n",
    "\n",
    "for test_ind in test_inds:\n",
    "    for i, step in enumerate(videos[test_ind]):\n",
    "        out_test += \"workflow_video_%02d-%04d.jpg, %d\\n\" % (test_ind + 1, i + 1, step_index[step])\n",
    "        \n",
    "open(\"../dataset2/valset_10b.txt\", \"w\").write(out_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_train = \"\"\n",
    "\n",
    "for train_ind in train_inds:\n",
    "    for i, step in enumerate(videos[train_ind]):\n",
    "        out_train += \"workflow_video_%02d-%04d.jpg, %d\\n\" % (train_ind + 1, i + 1, step_index[step])\n",
    "        \n",
    "open(\"../dataset2/trainset_10b.txt\", \"w\").write(out_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
