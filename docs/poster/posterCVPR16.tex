\documentclass[landscape,a0paper,fontscale=0.292]{baposter}
%\usepackage[english]{babel}
\usepackage[vlined]{algorithm2e}
\usepackage{times}
\usepackage{calc}
\usepackage{url}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{relsize}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{epstopdf}

\usepackage{graphicx}
\usepackage{multicol}
\usepackage[T1]{fontenc}
\usepackage{ae}
\usepackage{multirow}
\usepackage{rotating}

\usepackage{subcaption}

\usepackage{enumitem}
\setlist[enumerate]{leftmargin=*}

\graphicspath{{images/}}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\x}{\mathbf{x}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\h}{\mathbf{h}}
\newcommand{\w}{\mathbf{w}}

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 %%%% Some math symbols used in the text
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 % Format
 \newcommand{\RotUP}[1]{\begin{sideways}#1\end{sideways}}


 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 % Multicol Settings
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 \setlength{\columnsep}{0.7em}
 \setlength{\columnseprule}{0mm}


\definecolor{colorRed}{RGB}{0,50,255}%{120,120,120}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Begin of Document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Here starts the poster
%%---------------------------------------------------------------------------
%% Format it to your taste with the options
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{poster}{
 % Show grid to help with alignment
 grid=false,
 %Number of columns
 columns=4,
 % Column spacing
 colspacing=0.7em,
 % Color style
 headerColorOne=colorRed,
 borderColor=colorRed,
 % Format of textbox
 textborder=roundedsmall,
 % Format of text header
 headerborder=closed,
 headershape=smallrounded,
 headershade=plain,
 headerheight=0.16\textheight,
 headerFontColor=white,
 boxshade=none,
 background=none,
 bgColorOne=cyan!10!white}
 % Eye Catcher
 { 
    \begin{tabular}{c}
      \hspace{0.5cm}\includegraphics[width=4.5cm]{logo/logo_miccai.png} \\ \vspace{-.2cm}
      \\
      \hspace{0.2cm}\includegraphics[width=4cm]{logo/logo_m2cai.png}
    \end{tabular}
 }
 % Title
 {\sc \fontsize{0.7cm}{0.6cm}\selectfont M2CAI Workflow Challenge: Convolutional Neural \\ {\fontsize{0.7cm}{0.6cm}\selectfont Networks with Time Smoothing and Hidden Markov Model} \\for Video Frames Classification }
 % Authors
 {Remi \textsc{Cadene}, Thomas \textsc{Robert}, Nicolas \textsc{Thome}, Matthieu \textsc{Cord} \vspace{0.1cm}\\
 {\small Sorbonne Universit\'{e}s, UPMC Univ Paris 06, LIP6, Paris, France}
 } % University logo
 {
    \begin{tabular}{c}
    %  \includegraphics[height=0.07\textheight]{logo_LIP6} \\ %\vspace{0.1cm} 
          \hspace{-5mm}
      \includegraphics[height=0.075\textheight]{logo/logos.pdf}  \\
      \hspace{-10mm}
      \includegraphics[height=0.060\textheight]{logo/logo_labex.png} \hspace{8mm}
      \includegraphics[height=0.075\textheight]{logo/cnrs} 
    \end{tabular}
    
 }
 

 
 
 
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\headerbox{Context}{name=context,column=0,row=0,span=1}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\textbf{Goal:} Surgical video frames classification
 
$\triangleright$ Videos of size 1920x1080 Shot at 25 frames per second at IRCAD research center in Strasbourg, France

$\triangleright$ 27 training videos

$\triangleright$ 15 testing videos

$\triangleright$ 8 classes


 \begin{tabular}{cc}
\includegraphics[width=3.5cm]{../slides/images/m2cai.jpg}
& 
\includegraphics[width=3.5cm]{../slides/images/m2cai-2.jpg} 
\\
{\em Clean image} & {\em Noisy image}
\end{tabular}

\vspace{1mm}

$\triangleright$ Online prediction: $P(y | x_i, x_{i-1}, x_{i-2}, ...)$
 
%$\triangleright$ Supervision: full annotations ({\em e.g.} BB) expensive

$\triangleright$ Usefull to
%Weakly Supervised Learning (WSL) framework 

~~ $\triangleright$ Monitor surgeons

~~ $\triangleright$ Trigger automatic actions

%$\triangleright$ End-to-end training 

}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   \headerbox{Fully $\rightarrow$ Weakly Deep}{name=model,column=0,below=context}{
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 
% $\triangleright$ Standard deep architecture: VGG16
% 
% $\triangleright$ Problem: fixed-size image
% 
% $\triangleright$ Adapt architecture to WSL
% 
% ~~ $\triangleright$ Fully connected layer $\rightarrow$ convolution layer 
% 
% ~~~~~ $\triangleright$ Sliding window approach / shared features
% 
% ~~ $\triangleright$ Spatial aggregation 
% 
% ~~~~~ $\triangleright$ Perform object localization prediction
% 
% 
% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{Deep Learning Methods}{name=region,column=0,below=context, above=bottom}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Random split + sampling (1f/s):}

$\triangleright$ Training set: 22 videos (59,493 images)

$\triangleright$ Validation set: 5 videos (8,062 images)

$\triangleright$ Testing set: 15 videos (28,732 images)

\vspace{.1cm}

\textbf{"From Scratch" : End-to-End Learning}

\vspace{-.3cm}

\begin{center}
\includegraphics[width=6cm]{../slides/images/FromScratch.png}
\end{center}

\vspace{-.3cm}

\textbf{"Extraction" : Pre-trained CNN}

\vspace{-.3cm}

\begin{center}
\includegraphics[width=6cm]{../slides/images/Extraction.png}
\end{center}

\vspace{-.3cm}

\textbf{"Fine-Tuning" : Both approaches !}

\vspace{-.3cm}

\begin{center}
\includegraphics[width=6cm]{../slides/images/FineTuning.png}
\end{center}



}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{Comparison of Deep Learning architectures }{name=reso_results,column=1,row=0,span=2}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  
  \begin{minipage}{.8\textwidth}
  
\begin{center}
\includegraphics[width=11cm]{../slides/images/vgg16.png}
\end{center}

	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			Model & Type & Accuracy (\%) \\
			\hline\hline
			InceptionV3 $[$4$]$ & Extraction (repres. of ImageNet)& 60.53 \\
			InceptionV3 $[$4$]$ & From Scratch (repres. of M2CAI) & 69.13 \\
			InceptionV3 $[$4$]$ & Weldon $[$3$]$ (both representations) & 78.18 \\
			InceptionV3 $[$4$]$ & Fine-tuning (both representations) & 79.06 \\
			\textbf{ResNet200} $[$2$]$ & \textbf{Fine-tuning (both representations)} & \textbf{79.24} \\
			\hline
		\end{tabular}
	\end{center}
	
\end{minipage}
\begin{minipage}{.19\textwidth}
	
	\begin{center}
		\includegraphics[width=1.64cm]{images/resnet.png}
	\end{center}
	
	
\end{minipage}


}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{Comparison of Smoothing methods}{name=lr-cnn,column=1,span=2,below=reso_results,above=bottom}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{center}
% \begin{tabular}{cccccc}
% \hspace{-3.5mm}
%  \includegraphics[height=1.94cm]{000013} & \hspace{-4mm}
%  \includegraphics[height=1.94cm]{003006} & \hspace{-4mm}
%  \includegraphics[height=1.94cm]{2012_004308} & \hspace{-4mm}
%  \includegraphics[height=1.94cm]{COCO_7} & \hspace{-4mm}
%  \includegraphics[height=1.94cm]{15scene} & \hspace{-4mm}
%  \includegraphics[height=1.94cm]{bookstore} \\
%  \hspace{-4mm} VOC 2007 & \hspace{-4mm} VOC 2012 & \hspace{-4mm} VOC12 Action & \hspace{-4mm} COCO & \hspace{-4mm} 15 Scene & \hspace{-4mm} MIT67 
% \end{tabular}
% \end{center}

%\begin{minipage}[t]{8cm}

	\begin{center}
		\resizebox{300pt}{!}{%
		\begin{tabular}{|c|c|c|c|}
			\hline
			Temporal Method & Accuracy Val (\%) & Jaccard Val & Jaccard Test \\
			\hline\hline
			No Smoothing & 79.24 & -- & -- \\
			Avg Smoothing & 85.97 & 74.67 & -- \\
			\textbf{Avg + HMM Online} & \textbf{88.90} & \textbf{81.60} & \textbf{71.9} \\ \hline
			Avg + HMM Offline & 93.47 & 87.59 & -- \\
			\hline
		\end{tabular}}
	\end{center}

	\vspace{-.6cm}

		\begin{center}
			\includegraphics[width=14cm]{images/visu.png}
		\end{center}

%\end{minipage}


}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{Hidden Markov Model}{name=learning,column=3,row=0}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

$\triangleright$ Initial state probabilities

$\triangleright$ Matrix of probabilities of transition between states

$\triangleright$ Gaussian parameters for emissions of observations (mean and co-variance matrix)

\iffalse
	\begin{figure}
		\begin{subfigure}{.49\textwidth}
			\includegraphics[width=.90cm]{../slides/images/index.png}
			%			\caption{\small North-South (3479)}
			\label{fig:dsg1}
		\end{subfigure}%
		\begin{subfigure}{.49\textwidth}
			\centering
			\includegraphics[width=.90cm]{../slides/images/index.png}
			%		\caption{\small East-West (1856)}
			\label{fig:dsg2}
		\end{subfigure}
		%		\caption{8000 train images, 20760 no label, 13999 test images}
		\label{fig:dsgimages}
	\end{figure}
\fi

%\vspace{2mm}
\begin{tabular}{cc}
\hspace{-3mm} \includegraphics[width=3.9cm]{../slides/images/index.png} & \hspace{-4mm} \includegraphics[width=3.9cm]{../slides/images/index2.png} \\
\end{tabular}
%\vspace{-2mm}


%~~ $\triangleright$ Exact and efficient (loss-augmented) inference
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  \headerbox{Optimizing Ranking Metrics}{name=ranking,column=3,below=learning}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%$\triangleright$ Goal: predict a ranking matrix
%
%$\triangleright$ Optimized Average Precision
%
%$\triangleright$ Latent structured output formulation [2]
%
%$\triangleright$ Defined a surrogate upper-bound loss
%
%~~ $\triangleright$ Generalized MANTRA ranking instantiation
%
%~~ $\triangleright$ Exact and efficient (loss-augmented) inference
%
%}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\headerbox{Conclusion}{name=ouverture,column=3,above=bottom,below=learning}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textbf{Future works:}

$\triangleright$ Fine tuning CNN on full trainset (not only 80\%)

$\triangleright$ Ensembling several fine tuned CNNs


\textbf{Results are reproducible with Torch7:}

\url{github.com/Cadene/torchnet-m2caiworkflow}

\url{arxiv.org/abs/1610.05541}

\begin{center}
\begin{tabular}{cc}
 \includegraphics[width=2.5cm]{images/github.jpg} & \includegraphics[width=2.5cm]{images/github.jpg} \\
	Code & Paper
\end{tabular}
\end{center}


\vspace{0cm}

{
\scriptsize
\begin{enumerate}
\item [1] Cadene et al. Master's Thesis : Deep Learning for Visual Recognition. {\em arXiv}, 2016.
\item [2] He K. et al. Identity Mappings in Deep Residual Networks. {\em ECCV}, 2016.
\item [3] Durand et al. WELDON: Weakly Supervised Learning of Deep Convolutional Neural Networks. {\em CVPR}, 2016.
\item [4] Szeggedy et al. Rethinking the inception architecture for computer vision {\em CVPR}, 2015.
\item [5] Diederik et al. Adam: A Method for Stochastic Optimization. {\em ICLR}, 2014.
\item [6] Simonyan et al. Very deep convolutional networks for large-scale image recognition. {\em ICLR}, 2014.
\end{enumerate}
}

}

\end{poster}%
%
\end{document}
