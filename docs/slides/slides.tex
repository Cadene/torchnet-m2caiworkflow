\section{Context} \subsection{}\label{}

\begin{frame}{M2CAI Workflow Dataset}
	
		\begin{figure}
			\centering
			\includegraphics[width=.45\linewidth]{images/m2cai.jpg}
			%		\caption{80000 train images, 20000 test images, 101 classes}
			\label{fig:2images}
		\end{figure}
	
	Videos resolution is 1920 x 1080, shot at 25 frames per second at the IRCAD research center in Strasbourg, France.
	
	\begin{itemize}
		\item 27 training videos ranging from 15mn to 1hour%(67,595 images)
		%\item 22 train videos %(59,493 images)
		%\item 5 val videos %(8,062 images)
		\item 15 test videos %(28,732 images)
		%\item 8 classes (CleaningCoagulation, CalotTriangleDissection, CLippingCutting, etc.)
	\end{itemize}
	
\end{frame}

\begin{frame}{M2CAI Workflow Dataset}

	1 of 8 classes for each frames:
	\begin{itemize}
		\item TrocarPlacement
		\item Preparation
		\item CalotTriangleDissection
       	\item ClippingCutting
       	\item GallbladderDissection
       	\item GallbladderPackaging
       	\item CleaningCoagulation
       	\item GallbladderRetraction
    \end{itemize}

\end{frame}

\begin{frame}{M2CAI Workflow Goal and Measure}
	
		\begin{block}{Goal}
	  	Online prediction: $P(y | x_i, x_{i-1}, x_{i-2}, ...)$   \\
		$x_i$:= frame $i$, and $y$:= classes
		\end{block}
		
		%Detecting at which of the 8 phases of the operation each frames belong.
		
		
		\begin{block}{Useful to}
		\begin{itemize}
			\item Monitor surgeons
			\item Trigger automatic actions
		\end{itemize}
		\end{block}
		
		\begin{block}{Measures}
		\begin{itemize}
			\item Jaccard similarity coefficient:
	    $J(A,B) = \frac{| A \cap B |}{| A \cup B|} = \frac{| A \cap B |}{| A| + |B| - |A \cap B|}$
	    
	  		\item Accuracy top1: nb frames well classified / nb total frames
	  	\end{itemize}
	  	\end{block}
		
\end{frame}

\begin{frame}{Two fold approach}

	\begin{block}{1. Frames classifier using Deep Learning}
	\begin{itemize}
		\item From Scratch Convolutional Neural Network (CNN)
		\item Features Extraction CNN 
		\item Fine tuning CNN
	\end{itemize}
	\end{block}
	
	\begin{block}{2. Smoothing predictions}
	\begin{enumerate}	
		\item Averaging predictions over last 15 frames % However, the metric allows a 10 second-margin (not problematic)
		\item Hidden Markov Model (HMM) as a "denoizer" 
	\end{enumerate}
	\end{block}
	
\end{frame}


\section{Frames classifier} \subsection{}\label{}

\begin{frame}{Creating a trainset and valset of images}

	\begin{block}{Creating validation set by random split}
	\begin{itemize}
		\item Training set: 22 videos
		\item Validation set: 5 videos $\{2,9,10,13,27\}$
	\end{itemize}
	\end{block}	
	
	\begin{block}{Extracting one frame every 25 frames (1 frame per second)}
	\begin{itemize}
		\item Training set: 59,493 images
		\item Validation set: 8,062 images
		\item Testing set: 28,732 images
	\end{itemize}
	\end{block}
	

\end{frame}

\begin{frame}{Training CNN From Scratch}

	\begin{figure}[h]
		\centering
		\includegraphics[width=.80\linewidth]{images/vgg16.png}
		\caption{\small Vgg16 \cite{simonyan2014very}, top2 ILSVRC2014}
		\label{fig:quora-invariance-1}
	\end{figure}
	
\end{frame}

\begin{frame}{Using representations learned on ImageNet}
	
	\begin{block}{\small Pre-trained CNN as Features Extractor}
	\begin{enumerate}
		\item Extracting features somewhere
		\item Training a Support Vector Machine
	\end{enumerate}
	\end{block}
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=.70\linewidth]{images/vgg16.png}
	\end{figure}

\end{frame}


\begin{frame}{Adapting representations learned on Imagenet}

	\begin{block}{\small Fine tuning a pre-trained CNN}
	\begin{itemize}
		\item Same process than CNN From Scratch
		\item But smaller learning rate for pre-trained layers
	\end{itemize}
	\end{block}
	
	\begin{figure}[h]
		\centering
		\includegraphics[width=.79\linewidth]{images/vgg16.png}
	\end{figure}

\end{frame}

\begin{frame}{Which CNN to use ? Possible in production ?}

		\begin{table}[h]
		\centering
		\resizebox{300pt}{!}{%
			\begin{tabular}{|c|c|c|c|c|c|}
				\hline
				Model & Input & Param. & Depth & Implem. & Time (ms) \\ \hline \hline
				Vgg16 & 224 & 138M & 16 & GPU &  \\
				InceptionV3 & 399 & 24M & 42 & GPU & \textbf{0} \\
				ResNet-200  & 224 &  & 200 & GPU & \\ \hline
				InceptionV3 & 399 & 24M & 42 & CPU & 0 \\
				\hline
			\end{tabular}}
			\caption{\small Forward+Backward with batches of 30 images.} 
			\label{table:cnnbenchmark}
		\end{table}

\end{frame}

\begin{frame}{Comparison of frames classifiers}
	
	\begin{table}
	\begin{center}
		\begin{tabular}{|c|c|}
			\hline
			Classification Model & Accuracy (\%) \\
			\hline\hline
			InceptionV3 Extraction & 60.53 \\
			InceptionV3 From Scratch & 69.13 \\
			InceptionV3 Weldon & 78.18 \\
			InceptionV3 Fine-tuned & 79.06 \\
			ResNet200 Fine-tuned & 79.24 \\
			\hline
		\end{tabular}
	\end{center}
	\caption{Accuracy on the validation set.}
	\end{table}

\end{frame}


\section{Smoothing predictions} \subsection{}\label{}

\begin{frame}{Gaussian Hidden Markov Model}
	
	\begin{block}{HMM on the smoothed predictions over last 15 frames}
	\begin{itemize}
		\item the initial state probabilities
		\item the matrix of probabilities of transition between states 
		\item the emissions of observations (mean and co-variance)
	\end{itemize}
	\end{block}	
	
	\begin{figure}
		\centering
		\begin{subfigure}{.49\textwidth}
			\centering
			\includegraphics[width=.75\linewidth]{images/index.png}
			%			\caption{\small North-South (3479)}
			\label{fig:dsg1}
		\end{subfigure}%
		\begin{subfigure}{.49\textwidth}
			\centering
			\includegraphics[width=.75\linewidth]{images/index2.png}
			%		\caption{\small East-West (1856)}
			\label{fig:dsg2}
		\end{subfigure}
%		\caption{8000 train images, 20760 no label, 13999 test images}
		\label{fig:dsgimages}
	\end{figure}	
	
\end{frame}

\begin{frame}{Gaussian Hidden Markov Model}
	
	\begin{block}{Training process}
	Counting
	\end{block}
	
	\begin{block}{Testing process}
	Offline testing : Viterbi algorithm to obtain the most likely sequence of states
	
	Online testing : to predict $x_t$ we apply Viterbi on the sequence $y_1,...,y_t$
	\end{block}

\end{frame}
	

\begin{frame}{Comparison of temporal smoothing methods}

	\begin{table}
	\begin{center}
		\begin{tabular}{|c|c|c|c|}
			\hline
			Temporal Method & Accuracy Val (\%) & Jaccard Val & Jaccard Test \\
			\hline\hline
			Avg Smoothing & 85.97 & 74.67 & -- \\
			HMM Online & 88.90 & 81.60 & 71.\\
			HMM Offline & 93.47 & 87.59 & \\
			\hline
		\end{tabular}
	\end{center}
	\end{table}

\end{frame}

\begin{frame}{Visualization}

	\begin{figure}
\begin{center}
%\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   \includegraphics[width=1\linewidth]{../report/images/visu.png}
\end{center}
   \caption{Comparison of our temporal models predictions on the validation set. In blue, our ResNet200 Fine-tuned with average smoothing over 5 frames. In red, the offline predictions of an HMM trained of top of the latter model predictions. In mauve, the online predictions. In green, the ground truth label. }
\label{fig:long}
\label{fig:onecol}
\end{figure}	
	
\end{frame}


\section{Conclusion} \subsection{}\label{}

\begin{frame}{Conclusion}

	\begin{block}{Conclusion}
		\begin{itemize}
			\item Deep Learning efficient %to takle this problem
			\item Fine Tuning most accurate approach %to build a frames classifier
			\item HMM is usefull to smooth the predictions %to add a prior in order to smooth the predictions
		\end{itemize}
	\end{block}
	
	\begin{block}{Future work}
		\begin{itemize}
			\item train on 100\%
			\item ensembling
		\end{itemize}
	\end{block}
	
	Code available: \url{github.com/Cadene/torchnet-m2caiworkflow}
	
\end{frame}

\section{References} \subsection{}\label{references}

\begin{frame}[allowframebreaks]{References}
	
	\printbibliography[heading=none]
	
\end{frame}