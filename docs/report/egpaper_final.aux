\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{twinanda2016endonet}
\citation{sahu2016}
\citation{dergachyova2016}
\citation{jin2016}
\citation{Stauder2016}
\citation{simonyan2014very}
\@writefile{toc}{\contentsline {section}{\numberline {1}\hskip -1em.\nobreakspace  {}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}\hskip -1em.\nobreakspace  {}Our approach}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}\hskip -1em.\nobreakspace  {}Visual recognition: Deep CNN}{1}{section.2}}
\@writefile{toc}{\contentsline {paragraph}{Note about online data augmentation}{1}{section*.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}\hskip -1em.\nobreakspace  {}Pre-trained CNN as Features Extractor}{1}{subsection.2.1}}
\citation{szegedy2015rethinking}
\citation{Kingma14}
\citation{he2016deep}
\citation{LSUVInit2015}
\citation{durand2016weldon}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}\hskip -1em.\nobreakspace  {}Fine Tuning Pre-trained CNN}{2}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}\hskip -1em.\nobreakspace  {}Other Baselines}{2}{subsection.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}\hskip -1em.\nobreakspace  {}Temporal smoothing: Averaging and HMM}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}\hskip -1em.\nobreakspace  {}Averaging}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}\hskip -1em.\nobreakspace  {}Hidden Markov Model}{2}{subsection.3.2}}
\@writefile{toc}{\contentsline {paragraph}{Training}{2}{section*.2}}
\@writefile{toc}{\contentsline {paragraph}{Offline prediction}{2}{section*.3}}
\@writefile{toc}{\contentsline {paragraph}{Online prediction}{2}{section*.4}}
\bibstyle{ieee}
\bibdata{egbib}
\bibcite{dergachyova2016}{1}
\bibcite{durand2016weldon}{2}
\bibcite{he2016deep}{3}
\bibcite{jin2016}{4}
\bibcite{Kingma14}{5}
\bibcite{LSUVInit2015}{6}
\bibcite{sahu2016}{7}
\bibcite{simonyan2014very}{8}
\bibcite{Stauder2016}{9}
\bibcite{szegedy2015rethinking}{10}
\bibcite{twinanda2016endonet}{11}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Accuracy on the validation set.}}{3}{table.1}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Accuracy Top1 and Jaccard score on the validation set. The variance is computed over all classes.}}{3}{table.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}\hskip -1em.\nobreakspace  {}Post-processing to produce requested files}{3}{subsection.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}\hskip -1em.\nobreakspace  {}Experiments}{3}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}\hskip -1em.\nobreakspace  {}Classification models}{3}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}\hskip -1em.\nobreakspace  {}Temporal methods}{3}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5}\hskip -1em.\nobreakspace  {}Conclusion}{3}{section.5}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Jaccard score on the validation set.}}{4}{table.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison of our temporal models predictions on the validation set. In blue, our ResNet200 Fine-tuned with average smoothing over 5 frames. In red, the offline predictions of an HMM trained of top of the latter model predictions. In mauve, the online predictions. In green, the ground truth label. }}{5}{figure.1}}
\newlabel{fig:long}{{1}{5}{Comparison of our temporal models predictions on the validation set. In blue, our ResNet200 Fine-tuned with average smoothing over 5 frames. In red, the offline predictions of an HMM trained of top of the latter model predictions. In mauve, the online predictions. In green, the ground truth label}{figure.1}{}}
\newlabel{fig:onecol}{{1}{5}{Comparison of our temporal models predictions on the validation set. In blue, our ResNet200 Fine-tuned with average smoothing over 5 frames. In red, the offline predictions of an HMM trained of top of the latter model predictions. In mauve, the online predictions. In green, the ground truth label}{figure.1}{}}
